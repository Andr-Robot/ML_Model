{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomizedSearchCV\n",
    "RandomizedSearchCV 是一个可以代替 GridSearchCV的工具。通常，相比Grid Search，Randomized Search效率会更高。具体的原理如下：\n",
    "1. 对于搜索范围是分布的超参数，根据给定的分布随机采样；\n",
    "2. 对于搜索范围是list的超参数，在给定的list中进行等概率采样；\n",
    "3. 对前面两步中得到的n_iter组采样结果，进行遍历。\n",
    "4. 如果给定的搜索范围均为list，则不放回抽样n_iter次。\n",
    "5. 在sklearn中，交叉验证随机搜索的类为sklearn.model_selection.RandomizedSearchCV\n",
    "\n",
    "关键参数如下：\n",
    "- estimator: 模型\n",
    "- n_iter: 迭代次数查找次数\n",
    "- n_jobs: 并行数，设置为-1时，则用所有的处理器\n",
    "- cv: 交叉验证折数，不给则默认为5\n",
    "- error_score: 如果error了，记多少分。默认是'raise'，也就是报错，也可以选择一个分数，例如-1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基于XGB的随机搜索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "'''\n",
    "用于设置RandomizedSearchCV中模型的分布\n",
    "例如：查找连续值使用 uniform\n",
    "     uniform(1,5), 指的是从1-5间等可能选择浮点数; \n",
    "     查找整数值可以使用randint\n",
    "     randint(1,5), 指的是从1-5间等可能选择整数\n",
    "'''\n",
    "from scipy.stats import uniform, randint\n",
    "\n",
    "from xgboost import XGBRFClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "'''\n",
    "n_estimators: 从500-5000等可能选择整数\n",
    "learning_rate: 从这5个值中等可能地选择\n",
    "subsample: 从0.3-0.9等可能选择浮点数\n",
    "colsample_bytree: 从0.5-0.9等可能选择浮点数\n",
    "'''\n",
    "# params = {'n_estimators' : randint(500,5000), \n",
    "#           'learning_rate': [0.001, 0.01, 0.1, 0.2, 0, 3], \n",
    "#           'subsample': uniform(0.3, 0.9), \n",
    "#           'colsample_bytree': uniform(0.5, 0.9)\n",
    "#           }\n",
    "params = {'n_estimators' : [i for i in range(50, 501, 50)], \n",
    "          'learning_rate': [0.001, 0.01, 0.1, 0.2, 0, 3], \n",
    "          'subsample': [i / 10 for i in range(3, 10)], \n",
    "          'colsample_bytree': [i / 10 for i in range(5, 9)]\n",
    "          }\n",
    "\n",
    "xgb = XGBRFClassifier(objective='multi:softmax')\n",
    "'''\n",
    "使用xgb为estimator\n",
    "参数列表为 params\n",
    "n_iter:迭代次数1000\n",
    "评判标准为 accuracy\n",
    "注意：二分类时可以使用 scoring 可以设置为 roc_auc,多分类需要用 accuracy\n",
    "如果error了, 记为0分\n",
    "用所有的处理器进行计算\n",
    "'''\n",
    "clf = RandomizedSearchCV(xgb, \n",
    "                         param_distributions = params, \n",
    "                         n_iter = 200, \n",
    "                         scoring = 'accuracy', \n",
    "                         error_score = 0, \n",
    "                         verbose = 3, \n",
    "                         n_jobs = -1)\n",
    "\n",
    "# 开始搜索， 返回值中的model的参数是假的，看best estimator使用下面的命令\n",
    "clf.fit(X, y)\n",
    "\n",
    "# 查看最好的预测器\n",
    "print(clf.best_estimator_)\n",
    "\n",
    "# 输出最优参数\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基于深度学习的随机搜索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline    \n",
    "#为了能在notebook中显示图像\n",
    "import numpy as np\n",
    "import sklearn   \n",
    "import pandas as pd \n",
    "import os \n",
    "import sys \n",
    "import time \n",
    "import tensorflow as tf \n",
    "from tensorflow import keras \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing #从sklearn中引用加州的房价数据\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "print(housing.DESCR)\n",
    "print(housing.data.shape)\n",
    "print(housing.target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#引用train_test_split对数据集进行拆分\n",
    "# test_size 控制切分比例，默认切分比例3:1\n",
    "from sklearn.model_selection import train_test_split  \n",
    "\n",
    "#拆分数据集，加载数据集后返回训练集以及测试集\n",
    "x_train_all, x_test, y_train_all, y_test = train_test_split(housing.data, housing.target, random_state = 1) \n",
    "\n",
    "#将训练集进行一次拆分为验证集和测试集\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x_train_all, y_train_all, random_state=2)\n",
    "\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_valid.shape, y_valid.shape)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "#对数据进行归一化处理\n",
    "\n",
    "#由于transform处理处理数据时二维数组，所以要将数据转化一下\n",
    "#x_train: [none, 28, 28] -> [none, 784]\n",
    "#对于使用fit_transform 和transform 请参考我的TensorFlow中的博客\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_valid_scaled = scaler.transform(x_valid)\n",
    "x_test_scaled = scaler.transform(x_test)\n",
    "\n",
    "#注意在归一化数据后，之后使用的数据要使用新的归一化数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 以下展示如何实现随机超参数搜索\n",
    "\n",
    "# 1.将tf.keras.models。sequential转化为sklearn的model\n",
    "\n",
    "# 封装模型\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import reciprocal\n",
    "\n",
    "\n",
    "def bulid_model(hidden_layers=1, layer_size=30, learning_rate=3e-3):\n",
    "\n",
    "    # 使用序贯模型Sequential   tf.keras.models.sequential()\n",
    "    model = keras.models.Sequential()\n",
    "    # 第一个layer不循环创建，因为要输入input_shape,之后的layer可以循环创建\n",
    "    model.add(keras.layers.Dense(\n",
    "        layer_size, activation=\"relu\", input_shape=x_train.shape[1:]))\n",
    "    for _ in range(hidden_layers - 1):\n",
    "        model.add(keras.layers.Dense(layer_size, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    # 定义优化函数，使用自定义的learning_rate\n",
    "    optimizer = keras.optimizers.Adam(learning_rate)\n",
    "    # 编译compile\n",
    "    model.compile(loss=\"mean_squared_error\",  # 损失函数：使用均方根误差\n",
    "                  optimizer=optimizer,  # 优化函数\n",
    "                  )\n",
    "    return model\n",
    "\n",
    "\n",
    "# 转化模型  tf.keras.wrappers.scikit_learn.KerasRegressor\n",
    "sklearn_model = keras.wrappers.scikit_learn.KerasRegressor(bulid_model)\n",
    "\n",
    "# 2.定义要调整的超参数集合\n",
    "# scipy中的reciprocal函数用于实现分布，通过这个分布来实现学习率的超参数获取\n",
    "\n",
    "param_distribution = {\n",
    "    \"hidden_layers\": [1, 2, 3, 4],\n",
    "    \"layer_size\": np.arange(10, 100, 10),\n",
    "    \"learning_rate\": reciprocal(1e-4, 1e-2)\n",
    "}\n",
    "\n",
    "# 3.参数搜索 RandomizedSearchCV\n",
    "\n",
    "\n",
    "# RandomizedSearchCV参数说明，\n",
    "# clf1设置训练的学习器\n",
    "# param_dist字典类型，放入参数搜索范围\n",
    "# scoring = 'neg_log_loss'，精度评价方式设定为\"neg_log_loss\"\n",
    "# n_iter=300，训练300次，数值越大，获得的参数精度越大，但是搜索时间越长\n",
    "# n_jobs = -1，使用所有的CPU进行训练，默认为1，使用1个CPU\n",
    "# RandomizedSearchCV采用了cross-validation: 将训练集分成n分，n-1训练，最后一份验证。默认cv=3\n",
    "random_search_cv = RandomizedSearchCV(sklearn_model,\n",
    "                                      param_distribution,\n",
    "                                      cv=3,\n",
    "                                      n_iter=5,\n",
    "                                      n_jobs=1)\n",
    "# 使用回调函数\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(patience=5, min_delta=1e-3),\n",
    "]\n",
    "# 训练函数\n",
    "random_search_cv.fit(x_train_scaled, y_train,\n",
    "                     epochs=100,\n",
    "                     validation_data=(x_valid_scaled, y_valid),\n",
    "                     callbacks=callbacks)\n",
    "\n",
    "print(random_search_cv.best_params_)\n",
    "print(random_search_cv.best_score_)\n",
    "print(random_search_cv.best_estimator_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
